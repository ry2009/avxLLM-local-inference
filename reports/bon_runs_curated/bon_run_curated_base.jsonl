{"prompt": "2+2=", "answer": "4", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "4", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 1}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "3*3=", "answer": "9", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "9", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 1}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "5-2=", "answer": "3", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "3", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 1}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "Square root of 16 is", "answer": "4", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "4", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 1}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "The capital of France is", "answer": "Paris", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "Paris", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 5}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 6.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "The capital of Japan is", "answer": "Tokyo", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "Tokyo", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 5}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 6.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "The chemical symbol for water is", "answer": "H2O", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "H2O", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 3}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.75, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "What is the next number in the sequence 2, 4, 6, ?", "answer": "8", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "8", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 1}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 5.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "What color do you get by mixing red and blue?", "answer": "Purple", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "Purple", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 6}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 6.5, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
{"prompt": "Translate to English: 'Bonjour'", "answer": "Hello", "samples": [{"completion": "?", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 1}, {"completion": "I don't know", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 12}, {"completion": "Perhaps", "correct": false, "details": {}, "duration_s": 0.05, "length_chars": 7}, {"completion": "Hello", "correct": true, "details": {}, "duration_s": 0.05, "length_chars": 5}], "metrics": {"pass_at": {"1": 0.0, "4": 1.0, "8": 1.0, "16": 1.0}, "unique_frac": 1.0, "entropy": 0.5623, "avg_completion_length": 6.25, "avg_duration_s": 0.05, "avg_chars_per_sec": 40.0}, "config": {"k_values": [4, 8, 16], "samples_per_prompt": 4, "temperature": 0.8, "top_p": 0.95, "max_new_tokens": 12}, "adapter": {"base_model": "EleutherAI/pythia-70m-deduped", "adapter_name": null, "adapter_path": null}, "scorer": "exact", "metadata": {"experiment": "curated-base"}, "timestamp": "20251030T060000Z"}
